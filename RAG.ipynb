{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13b555a7-1c1a-4adb-9ffb-436ed0b47e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores.base import VectorStoreRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf33200-9c41-44cb-91a2-2643ecb0e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bb10a-048b-4244-8f5c-be224ce8c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('/mnt/code/documentation-main/content/user_guide/', recursive='true')\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c33fb-207f-49df-99cf-1d78153b41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk your data up into smaller documents\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "texts = text_splitter.split_documents(docs)\n",
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "411c6a64-997d-4358-a325-5af5e5944f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 654 documents\n"
     ]
    }
   ],
   "source": [
    "print (f'There are now {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9de964ee-75d0-452f-a930-f4313f27ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create embeddings of your documents to get ready for semantic search\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pickle\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "store = FAISS.from_texts([t.page_content for t in texts], embeddings)\n",
    "with open(\"faiss_doc_store.pkl\", \"wb\") as f:\n",
    "    pickle.dump(store, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3447b7d-9825-44a5-8b7d-dfb5ba0f6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f0ed1ee-3d89-4077-a2c3-a5f4f64159e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions about information in Domino Data Labs product documentation.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If the question is not about AI or ML or data science or MLOps or related to Domino Data Lab, politely inform them that you are tuned to only answer questions about MLOps, data science and Domino Data Lab.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4eea5764-f8b1-4ce8-a97b-e081cf314e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condense_prompt_qa_chain(store):\n",
    "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\", return_messages=True)\n",
    "    # see: https://github.com/langchain-ai/langchain/issues/5890\n",
    "    model = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=VectorStoreRetriever(vectorstore=store),\n",
    "        memory=memory,\n",
    "        combine_docs_chain_kwargs={\"prompt\": QA_PROMPT})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03c65c4b-bd9a-4a04-9595-71eb5bca0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from the pickle file; change the location if needed\n",
    "if 'store' not in locals() or store is None:\n",
    "    with open(\"faiss_doc_store.pkl\", \"rb\") as f:\n",
    "        store = pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad64be3b-f72f-4929-bed1-48a55e549f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = get_condense_prompt_qa_chain(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86f11c3f-9497-41e6-94cb-6d306f87dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa({\"question\": \"What is a Domino data set\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae31c0a5-2d61-466e-b770-74d4c2595df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Domino data set is a managed folder within Domino Datasets that allows you to store and manage data within the Domino system. It provides several advantages over storing data in project files, such as the ability to store more files, bigger files, and access them faster. There is no limit to the number of files that can be stored in a Domino data set, and there is no limit to the size of any individual file stored in a data set. Additionally, data sets are attached to executors as networked file systems, eliminating the need to transfer their contents when starting a run or workspace. This makes it easier to organize and share curated subsets of data with your team members.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5dcf64e-a07f-42d7-af2f-2c711bdcc125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The advantages of using a Domino data set for storing and managing data within the Domino system are:\\n\\n1. Support for larger data: Domino data sets can handle much larger data than project artifacts, allowing you to store and manage data sets up to ~1TB per data set and hundreds of TB across multiple data sets.\\n\\n2. Reproducibility: Domino data sets support snapshots, which means you can version your data sets and easily reproduce previous versions. This is particularly useful for training sets that can't easily be shared or controlled outside of Domino.\\n\\n3. Flexibility in accessing data: Domino data sets provide a single interface for accessing all of your data, regardless of where it lives. You can connect Domino to popular data services using data source connectors or directly connect to any data service using the same code you use in your local environment.\\n\\n4. Shareability: Domino data sets are shareable within the Domino system, allowing you to easily collaborate and share data with team members. You can read and write to managed folders within Domino, making it simple to use and share data.\\n\\nOverall, using Domino data sets provides a scalable and flexible solution for storing and managing data within the Domino system, with support for larger data sizes, reproducibility, and easy sharing and collaboration.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa({\"question\": \"What is a Domino data set\"})['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71412495-cbdc-4e52-b074-56bf93794d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
