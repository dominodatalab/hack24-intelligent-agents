{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afce9655-4924-4f31-9bc0-5edf1486cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from domino import Domino\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chains import LLMMathChain\n",
    "# from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain.agents import AgentExecutor, AgentType, initialize_agent, create_csv_agent\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool, DuckDuckGoSearchRun\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319e994b-766a-4325-85ae-a8e2bf5153f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Your OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2f9513-7b52-4296-9d2f-94d1231855bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c71238-f0fe-4bba-9330-31f77c7d3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search_tool = Tool.from_function(\n",
    "    func=search.run,\n",
    "    name=\"Search\",\n",
    "    description=\"useful for when you need to search the internet for information\"\n",
    ")\n",
    "\n",
    "llm_math_chain = LLMMathChain.from_llm(ChatOpenAI())\n",
    "\n",
    "math_tool = Tool.from_function(\n",
    "    func=llm_math_chain.run,\n",
    "    name=\"Calculator\",\n",
    "    description=\"Useful for when you are asked to perform math calculations\"\n",
    ")\n",
    "\n",
    "# create an experiment in MLflow\n",
    "@tool(\"create_experiment\", return_direct=True)\n",
    "def create_experiment(experiment_name:str):\n",
    "    \"\"\"Create an experiment in Domino\"\"\"\n",
    "    # we'll make the name unique in the project by appending a timestamp so that you and other users can run this cell more than once.\n",
    "    timestamp = time.time()\n",
    "    if experiment_name:\n",
    "        experiment_name = f\"{experiment_name}-{timestamp}\"\n",
    "        # below, we'll use the returned experiment_id in calls to mlflow.start_run() to add data to the experiment.\n",
    "        experiment_id = mlflow.create_experiment(experiment_name.replace(\"experiment_name = \\\"\", \"\"))\n",
    "        print(f\"Experiment id: {experiment_id}\")\n",
    "        print(f\"Experiment name: {experiment_name}\")\n",
    "\n",
    "\n",
    "# execute a blocking job in Domino\n",
    "@tool(\"create_run_job\", return_direct=True)\n",
    "def create_run_job(job_file:str):\n",
    "    \"\"\"Create and run  a job in Domino\"\"\"\n",
    "\n",
    "    owner=os.getenv(\"DOMINO_PROJECT_OWNER\")\n",
    "    project=os.getenv(\"DOMINO_PROJECT_NAME\")\n",
    "\n",
    "    domino = Domino(\n",
    "    f\"{owner}/{project}\",\n",
    "    api_key=os.environ[\"DOMINO_USER_API_KEY\"],\n",
    "    host=os.environ[\"DOMINO_API_HOST\"],\n",
    "    )\n",
    "    domino.authenticate(domino_token_file = os.getenv('DOMINO_TOKEN_FILE'))\n",
    "    if job_file:\n",
    "        # Blocking: this will start the run and wait for the run to finish before returning the status of the run\n",
    "        domino_run = domino.runs_start_blocking(\n",
    "            [job_file], title=\"Started from Domino agent\"\n",
    "        )\n",
    "    print(domino_run)\n",
    "\n",
    "# analyze control centre costs\n",
    "@tool(\"analyze_costs\", return_direct=True)\n",
    "def analyze_costs(user_query:str) -> str:\n",
    "    \"\"\"Answer usage and cost analytics related questions for this deployment\"\"\"\n",
    "    if not user_query:\n",
    "        return None\n",
    "    # get all the data and write it to a csv\n",
    "    csv_file_name = 'control_centre_costs.csv'\n",
    "    API_KEY = os.environ[\"DOMINO_USER_API_KEY\"]\n",
    "    URL = \"https://johnal33586.marketing-sandbox.domino.tech/v4/gateway/runs/getByBatchId\"\n",
    "    headers = {'X-Domino-Api-Key': API_KEY}\n",
    "    last_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    last_date = datetime.strftime(\n",
    "        datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days = 1),\n",
    "        '%Y-%m-%d',\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "      os.remove(csv_file_name)\n",
    "    except:\n",
    "      pass\n",
    "    \n",
    "    batch_ID_param = \"\"\n",
    "    while True:\n",
    "        batch = requests.get(url = URL + batch_ID_param, headers = headers)\n",
    "        parsed = json.loads(batch.text)\n",
    "        batch_ID_param = \"?batchId=\" + parsed['nextBatchId']\n",
    "        df = pd.DataFrame(parsed['runs'])\n",
    "        df[df.endTime <= last_date].to_csv(\n",
    "            csv_file_name,\n",
    "            mode=\"a+\",\n",
    "            index=False,\n",
    "            header=True)\n",
    "        if len(df.index) < 1000 or len(df.index) > len(df[df.endTime <= last_date].index):\n",
    "            break\n",
    "            \n",
    "    # create a csv agent\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    agent_csv = create_csv_agent(\n",
    "    llm,\n",
    "    \"control_centre_costs.csv\",\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=False\n",
    "    )\n",
    "    return agent_csv.run(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab714b3c-dd87-4cf0-a2cb-307925f69604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, math_tool,create_experiment,create_run_job, analyze_costs]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "393fb178-9b27-436d-b4dc-52b168cee0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Domino data set is a read-write folder that allows for efficient storage and sharing of large amounts of data across projects in the Domino Data Lab platform.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is a Domino data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4982628b-1ec0-42a0-978d-1d59caa78034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment id: 12\n",
      "Experiment name: experiment_name = \"agent_exp-1704851032.4947498\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"create an experiment called agent_exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc9644b-f4bc-4bb8-8582-085c76f917b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The headquarters of Domino Data Lab is located in San Francisco, California.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Where is Domino data lab located?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4a550ab-3647-4dec-942e-8e23b571bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': '659df7360ba3b8384bafdafa', 'message': 'Run for project integration-test/SearchEngineAgent started. You can view it here:\\nhttps://johnal33586.marketing-sandbox.domino.tech/jobs/integration-test/SearchEngineAgent/659df7360ba3b8384bafdafa\\n'}\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"Run a job using job.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa0ab3cf-5940-406c-bae4-17afd4803ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over 20% of the Fortune 100 companies have Domino Data Lab.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What % of Fortune 100 has Domino Data Lab?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6fd9f0c-2208-406b-84a8-ebc4696b818b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Domino Data Lab has launched powerful new capabilities for building AI, including Generative AI (GenAI), rapidly and safely at scale. These capabilities are part of their fall 2023 platform release and include transforming Domino's AI Project Hub into an AI ecosystem hub. The new features aim to accelerate AI innovation and production with scalability and safety in mind. They also include updates for accelerating AI time-to-value, reducing costs, implementing responsible AI, and expanded cloud-based offerings.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What new features were launched in Domino Data Lab, give me a 200 word summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79e33389-1936-42f9-9758-8541e94816bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The project that used the most compute hours is \"SearchEngineAgent\".'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Which project used the most number of compute hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29a2cad7-e5ba-4ce5-b798-b7431b7bdc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The usage hours for the project \"SearchEngineAgent\" on this deployment is approximately 11.98 hours.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many hours did the project SearchEngineAgent use on this deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6e98f-5931-49d0-987f-976581eb5780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
