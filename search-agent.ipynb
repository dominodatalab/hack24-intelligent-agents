{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afce9655-4924-4f31-9bc0-5edf1486cdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from domino import Domino\n",
    "\n",
    "from langchain import LLMMathChain\n",
    "from langchain.agents import AgentExecutor, AgentType, create_csv_agent, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool, DuckDuckGoSearchRun\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "319e994b-766a-4325-85ae-a8e2bf5153f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Your OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec2f9513-7b52-4296-9d2f-94d1231855bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92c71238-f0fe-4bba-9330-31f77c7d3a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/langchain/chains/llm_math/base.py:56: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search_tool = Tool.from_function(\n",
    "    func=search.run,\n",
    "    name=\"Search\",\n",
    "    description=\"useful for when you need to search the internet for information\"\n",
    ")\n",
    "\n",
    "llm_math_chain = LLMMathChain(llm=llm, verbose=True)\n",
    "\n",
    "math_tool = Tool.from_function(\n",
    "    func=llm_math_chain.run,\n",
    "    name=\"Calculator\",\n",
    "    description=\"Useful for when you are asked to perform math calculations\"\n",
    ")\n",
    "\n",
    "# create an experiment in MLflow\n",
    "@tool(\"create_experiment\", return_direct=True)\n",
    "def create_experiment(experiment_name:str):\n",
    "    \"\"\"Create an experiment in Domino\"\"\"\n",
    "    # we'll make the name unique in the project by appending a timestamp so that you and other users can run this cell more than once.\n",
    "    timestamp = time.time()\n",
    "    if experiment_name:\n",
    "        experiment_name = f\"{experiment_name}-{timestamp}\"\n",
    "        # below, we'll use the returned experiment_id in calls to mlflow.start_run() to add data to the experiment.\n",
    "        experiment_id = mlflow.create_experiment(experiment_name.replace(\"experiment_name = \\\"\", \"\"))\n",
    "        print(f\"Experiment id: {experiment_id}\")\n",
    "        print(f\"Experiment name: {experiment_name}\")\n",
    "\n",
    "\n",
    "# execute a blocking job in Domino\n",
    "@tool(\"create_run_job\", return_direct=True)\n",
    "def create_run_job(job_file:str):\n",
    "    \"\"\"Create and run  a job in Domino\"\"\"\n",
    "    domino = Domino(\n",
    "    f\"{owner}/{project}\",\n",
    "    api_key=os.environ[\"DOMINO_USER_API_KEY\"],\n",
    "    host=os.environ[\"DOMINO_API_HOST\"],\n",
    "    )\n",
    "    domino.authenticate(domino_token_file = os.getenv('DOMINO_TOKEN_FILE'))\n",
    "    if job_file:\n",
    "        # Blocking: this will start the run and wait for the run to finish before returning the status of the run\n",
    "        domino_run = domino.runs_start_blocking(\n",
    "            [job_file], title=\"Started from Domino agent\"\n",
    "        )\n",
    "    print(domino_run)\n",
    "\n",
    "# analyze control centre costs\n",
    "@tool(\"analyze_costs\", return_direct=True)\n",
    "def analyze_costs(user_query:str) -> str:\n",
    "    \"\"\"Answer usage and cost analytics related questions for this deployment\"\"\"\n",
    "    if not user_query:\n",
    "        return None\n",
    "    # get all the data and write it to a csv\n",
    "    csv_file_name = 'control_centre_costs.csv'\n",
    "    API_KEY = os.environ[\"DOMINO_USER_API_KEY\"]\n",
    "    URL = \"https://johnal33586.marketing-sandbox.domino.tech/v4/gateway/runs/getByBatchId\"\n",
    "    headers = {'X-Domino-Api-Key': API_KEY}\n",
    "    last_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    last_date = datetime.strftime(\n",
    "        datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days = 1),\n",
    "        '%Y-%m-%d',\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "      os.remove(csv_file_name)\n",
    "    except:\n",
    "      pass\n",
    "    \n",
    "    batch_ID_param = \"\"\n",
    "    while True:\n",
    "        batch = requests.get(url = URL + batch_ID_param, headers = headers)\n",
    "        parsed = json.loads(batch.text)\n",
    "        batch_ID_param = \"?batchId=\" + parsed['nextBatchId']\n",
    "        df = pd.DataFrame(parsed['runs'])\n",
    "        df[df.endTime <= last_date].to_csv(\n",
    "            csv_file_name,\n",
    "            mode=\"a+\",\n",
    "            index=False,\n",
    "            header=True)\n",
    "        if len(df.index) < 1000 or len(df.index) > len(df[df.endTime <= last_date].index):\n",
    "            break\n",
    "            \n",
    "    # create a csv agent\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    agent_csv = create_csv_agent(\n",
    "    llm,\n",
    "    \"control_centre_costs.csv\",\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=False\n",
    "    )\n",
    "    return agent_csv.run(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab714b3c-dd87-4cf0-a2cb-307925f69604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool, math_tool,create_experiment,create_run_job, analyze_costs]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "393fb178-9b27-436d-b4dc-52b168cee0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Domino data set is a read-write folder for storing and sharing data in the Domino Data Lab platform.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is a Domino data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4982628b-1ec0-42a0-978d-1d59caa78034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment id: 11\n",
      "Experiment name: experiment_name = \"agent_exp-1704842376.6161933\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"create an experiment called agent_exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5bc9644b-f4bc-4bb8-8582-085c76f917b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Domino Data Lab is located at 135 Townsend St Fl 5, San Francisco, California, 94107.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Where is Domino data lab located?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d4a550ab-3647-4dec-942e-8e23b571bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'runId': '659dd4930ba3b8384bafda7d', 'message': 'Run for project integration-test/SearchEngineAgent started. You can view it here:\\nhttps://johnal33586.marketing-sandbox.domino.tech/jobs/integration-test/SearchEngineAgent/659dd4930ba3b8384bafda7d\\n'}\n"
     ]
    }
   ],
   "source": [
    "agent.run(\"Run a job using job.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa0ab3cf-5940-406c-bae4-17afd4803ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over 20% of the Fortune 100 companies have Domino Data Lab.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What % of Fortune 100 has Domino Data Lab?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6fd9f0c-2208-406b-84a8-ebc4696b818b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Domino Data Lab has launched powerful new capabilities for building AI, including Generative AI (GenAI), rapidly and safely at scale. They have also introduced an AI Project Hub that streamlines the development process by providing pre-trained foundation models and project templates for 1-click turnkey solutions. Additionally, Domino Data Lab has released updates for accelerating AI time-to-value, reducing costs, implementing responsible AI, and expanding their cloud-based offerings. These new features aim to optimize the application of AI in companies and enable them to leverage its business possibilities.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What new features were launched in Domino Data Lab, give me a 200 word summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79e33389-1936-42f9-9758-8541e94816bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/langchain/agents/agent_toolkits/pandas/base.py:289: LangChainPendingDeprecationWarning: On 2023-10-27 this module will be be deprecated from langchain, and will be available from the langchain-experimental package.This code is already available in langchain-experimental.See https://github.com/langchain-ai/langchain/discussions/11680.\n",
      "  warn_deprecated(\n",
      "/home/ubuntu/.local/lib/python3.9/site-packages/langchain/tools/python/tool.py:140: LangChainPendingDeprecationWarning: On 2023-10-27 this module will be be deprecated from langchain, and will be available from the langchain-experimental package.This code is already available in langchain-experimental.See https://github.com/langchain-ai/langchain/discussions/11680.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The project that used the most compute hours is \"SearchEngineAgent\".'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Which project used the most number of compute hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "29a2cad7-e5ba-4ce5-b798-b7431b7bdc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/langchain/agents/agent_toolkits/pandas/base.py:289: LangChainPendingDeprecationWarning: On 2023-10-27 this module will be be deprecated from langchain, and will be available from the langchain-experimental package.This code is already available in langchain-experimental.See https://github.com/langchain-ai/langchain/discussions/11680.\n",
      "  warn_deprecated(\n",
      "/home/ubuntu/.local/lib/python3.9/site-packages/langchain/tools/python/tool.py:140: LangChainPendingDeprecationWarning: On 2023-10-27 this module will be be deprecated from langchain, and will be available from the langchain-experimental package.This code is already available in langchain-experimental.See https://github.com/langchain-ai/langchain/discussions/11680.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The usage hours for the project \"SearchEngineAgent\" on this deployment is approximately 8.82 hours.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"How many hours did the project SearchEngineAgent use on this deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef6e98f-5931-49d0-987f-976581eb5780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
